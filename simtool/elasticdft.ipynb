{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "DESCRIPTION"
    ]
   },
   "outputs": [],
   "source": [
    "DESCRIPTION = \"\"\"Using quantum espresso to compute the stresses associated with different strain states and fitting the elastic tensor.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymatgen.io.pwscf import PWInput\n",
    "from pymatgen.core import Structure\n",
    "from pymatgen.analysis.elasticity import *\n",
    "from pymatgen.io.vasp.inputs import *\n",
    "from pymatgen.core.tensors import symmetry_reduce\n",
    "from pymatgen.symmetry.analyzer import SpacegroupAnalyzer\n",
    "import os\n",
    "\n",
    "from simtool import getValidatedInputs, DB, findInstalledSimToolNotebooks, searchForSimTool\n",
    "import nanohubremote as nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml INPUTS\n",
    "\n",
    "mp_id:\n",
    "    type: Text\n",
    "    description: Materials Project ID for chosen structure\n",
    "        \n",
    "squid_id:\n",
    "    type: Text\n",
    "    description: Simulation ID for relaxed structure from CellRelaxDFT\n",
    "        \n",
    "strains:\n",
    "    type: List\n",
    "    description: List of strain magnitudes\n",
    "        \n",
    "shears:\n",
    "    type: List\n",
    "    description: List of shear magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "defaultInputs = getValidatedInputs(INPUTS)\n",
    "if defaultInputs:\n",
    "    globals().update(defaultInputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "FILES"
    ]
   },
   "outputs": [],
   "source": [
    "EXTRA_FILES = ['pseudo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T01:49:50.449072Z",
     "start_time": "2024-03-11T01:49:50.445013Z"
    }
   },
   "outputs": [],
   "source": [
    "%%yaml OUTPUTS\n",
    "\n",
    "external_pressure:\n",
    "    type: Number\n",
    "    description: External pressure of the prestine structure queried from CellRelaxDFT\n",
    "    units: gigapascal\n",
    "\n",
    "strain_matrices:\n",
    "    type: Array\n",
    "    description: Array of strain matrices that were actually used in the generation of the deformed structures and fitting of the elastic tensor (only different from the input if sym_red is True)\n",
    "        \n",
    "stress_tensors:\n",
    "    type: Array\n",
    "    description: Array of stress tensors as arrays that were computed by quantum espresso for each deformed structure and used in the fit for the elastic tensor\n",
    "\n",
    "deformed_structures:\n",
    "    type: List\n",
    "    description: List of pymatgen Structure objects in dictionary format that were generated by the applying strains to the pristine structure\n",
    "        \n",
    "energies:\n",
    "    type: List\n",
    "    description: List of energies per formula unit from the DFT calculations on each deformed structure\n",
    "    \n",
    "elastic_tensor:\n",
    "    type: Array\n",
    "    description: Elastic tensor in voigt notation fit with pymatgen using the Moore-Penrose pseudo-inverse method\n",
    "        \n",
    "C11:\n",
    "    type: Number\n",
    "    description: Elastic constant C11\n",
    "    units: gigapascal\n",
    "        \n",
    "C12:\n",
    "    type: Number\n",
    "    description: Elastic constant C12\n",
    "    units: gigapascal\n",
    "        \n",
    "C13:\n",
    "    type: Number\n",
    "    description: Elastic constant C13\n",
    "    units: gigapascal\n",
    "        \n",
    "C14:\n",
    "    type: Number\n",
    "    description: Elastic constant C14\n",
    "    units: gigapascal\n",
    "        \n",
    "C15:\n",
    "    type: Number\n",
    "    description: Elastic constant C15\n",
    "    units: gigapascal\n",
    "        \n",
    "C16:\n",
    "    type: Number\n",
    "    description: Elastic constant C16\n",
    "    units: gigapascal\n",
    "        \n",
    "C22:\n",
    "    type: Number\n",
    "    description: Elastic constant C22\n",
    "    units: gigapascal\n",
    "        \n",
    "C23:\n",
    "    type: Number\n",
    "    description: Elastic constant C23\n",
    "    units: gigapascal\n",
    "        \n",
    "C24:\n",
    "    type: Number\n",
    "    description: Elastic constant C24\n",
    "    units: gigapascal\n",
    "        \n",
    "C25:\n",
    "    type: Number\n",
    "    description: Elastic constant C25\n",
    "    units: gigapascal\n",
    "        \n",
    "C26:\n",
    "    type: Number\n",
    "    description: Elastic constant C26\n",
    "    units: gigapascal\n",
    "        \n",
    "C33:\n",
    "    type: Number\n",
    "    description: Elastic constant C33\n",
    "    units: gigapascal\n",
    "        \n",
    "C34:\n",
    "    type: Number\n",
    "    description: Elastic constant C34\n",
    "    units: gigapascal\n",
    "        \n",
    "C35:\n",
    "    type: Number\n",
    "    description: Elastic constant C35\n",
    "    units: gigapascal\n",
    "        \n",
    "C36:\n",
    "    type: Number\n",
    "    description: Elastic constant C36\n",
    "    units: gigapascal\n",
    "\n",
    "C44:\n",
    "    type: Number\n",
    "    description: Elastic constant C44\n",
    "    units: gigapascal\n",
    "        \n",
    "C45:\n",
    "    type: Number\n",
    "    description: Elastic constant C45\n",
    "    units: gigapascal\n",
    "        \n",
    "C46:\n",
    "    type: Number\n",
    "    description: Elastic constant C46\n",
    "    units: gigapascal\n",
    "        \n",
    "C55:\n",
    "    type: Number\n",
    "    description: Elastic constant C55\n",
    "    units: gigapascal\n",
    "        \n",
    "C56:\n",
    "    type: Number\n",
    "    description: Elastic constant C56\n",
    "    units: gigapascal\n",
    "        \n",
    "C66:\n",
    "    type: Number\n",
    "    description: Elastic constant C66\n",
    "    units: gigapascal\n",
    "        \n",
    "bulk_modulus_reuss:\n",
    "    type: Number\n",
    "    description: Bulk modulus derived from the elastic tensor using the Reuss method (constant strain)\n",
    "    units: gigapascal\n",
    "        \n",
    "bulk_modulus_voigt:\n",
    "    type: Number\n",
    "    description: Bulk modulus derived from the elastic tensor using the Voigt method (constant stress)\n",
    "    units: gigapascal\n",
    "        \n",
    "bulk_modulus_vrh:\n",
    "    type: Number\n",
    "    description: Bulk modulus derived from the elastic tensor using the Voigt-Reuss-Hill method (average of Reuss and Voigt)\n",
    "    units: gigapascal\n",
    "        \n",
    "shear_modulus_reuss:\n",
    "    type: Number\n",
    "    description: Shear modulus derived from the elastic tensor using the Reuss method (constant strain)\n",
    "    units: gigapascal\n",
    "        \n",
    "shear_modulus_voigt:\n",
    "    type: Number\n",
    "    description: Shear modulus derived from the elastic tensor using the Voigt method (constant stress)\n",
    "    units: gigapascal\n",
    "        \n",
    "shear_modulus_vrh:\n",
    "    type: Number\n",
    "    description: Shear modulus derived from the elastic tensor using the Voigt-Reuss-Hill method (average of Reuss and Voigt)\n",
    "    units: gigapascal\n",
    "        \n",
    "homogeneous_poisson:\n",
    "    type: Number\n",
    "    description: Homogeneous poisson ratio derived from the elastic tensor\n",
    "        \n",
    "youngs_modulus:\n",
    "    type: Number\n",
    "    description: Youngs modulus derived from the elastic tensor\n",
    "    units: gigapascal\n",
    "        \n",
    "calc_params:\n",
    "    type: Dict\n",
    "    description: Dictionary of various DFT parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_data = { 'grant_type' : 'tool' }\n",
    "with open(os.environ[\"SESSIONDIR\"]+\"/resources\") as file:\n",
    "    lines = [line.split(\" \", 1) for line in file.readlines()]\n",
    "    properties = {line[0].strip(): line[1].strip() for line in lines if len(line)==2}\n",
    "    auth_data[\"sessiontoken\"] = properties[\"session_token\"]\n",
    "    auth_data[\"sessionnum\"] = properties[\"sessionid\"]\n",
    "    \n",
    "session = nr.Session(auth_data, url='https://nanohub.org/api')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = 'cellrelaxdft'\n",
    "\n",
    "revisions = [0]\n",
    "\n",
    "data_list = {}\n",
    "\n",
    "for revision in revisions:\n",
    "    search = {\n",
    "            'tool':tool,\n",
    "            'filters':json.dumps([\n",
    "                                  {'field':'squid','operation':'==','value':squid_id},\n",
    "                                ]),\n",
    "            'results':json.dumps([\n",
    "                                'input.mp_id',\n",
    "                                'input.pseudo',\n",
    "                                'input.vdw_corr',\n",
    "                                'input.KE_cutoff',\n",
    "                                'input.i_steps',\n",
    "                                'input.e_steps',\n",
    "                                'input.scf_conv',\n",
    "                                'input.energy_conv',\n",
    "                                'input.force_conv',\n",
    "                                'input.spin_polar',\n",
    "                                'input.is_metal',\n",
    "                                'input.hubbard_U_on',\n",
    "                                'input.hubbard_projector',\n",
    "                                'input.hubbard_U_values',\n",
    "                                'input.hubbard_U_orbitals',\n",
    "                                'output.pressure',\n",
    "                                'output.structure_dict'\n",
    "                                ]),    \n",
    "            'limit':10000,    \n",
    "            'revision':revision,\n",
    "            'simtool' : 1\n",
    "             }\n",
    "\n",
    "    req_json = session.requestPost('results/dbexplorer/search', data=search, timeout=60)\n",
    "    req_json = req_json.json()\n",
    "    data_list[f'{revision}'] = pd.DataFrame(req_json['results'])\n",
    "\n",
    "\n",
    "data = pd.concat([data_list[f'{revision}'] for revision in revisions], axis=0, ignore_index=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "mp_id_cellrelaxdft = data['input.mp_id'][0]\n",
    "if mp_id != mp_id_cellrelaxdft:\n",
    "    raise ValueError(f'{mp_id} is not the same as what is retreived using squid: {mp_id_cellrelaxdft}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct = Structure.from_dict(data['output.structure_dict'][0], fmt='cif')\n",
    "sga = SpacegroupAnalyzer(struct)\n",
    "struct = sga.get_conventional_standard_structure()\n",
    "n_atoms = struct.num_sites\n",
    "n_atom_types = len(struct.elements)\n",
    "is_metal = data['input.is_metal'][0]\n",
    "ext_press = data['output.pressure'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_metal:\n",
    "    k_x = round((1/struct.lattice.abc[0])*(2*np.pi)/0.16)\n",
    "    k_y = round((1/struct.lattice.abc[1])*(2*np.pi)/0.16)\n",
    "    k_z = round((1/struct.lattice.abc[2])*(2*np.pi)/0.16)\n",
    "else:\n",
    "    k_x = round((1/struct.lattice.abc[0])*(2*np.pi)/0.22)\n",
    "    k_y = round((1/struct.lattice.abc[1])*(2*np.pi)/0.22)\n",
    "    k_z = round((1/struct.lattice.abc[2])*(2*np.pi)/0.22)\n",
    "    \n",
    "KE_cutoff = data['input.KE_cutoff'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_steps = data['input.i_steps'][0]\n",
    "e_steps = data['input.e_steps'][0]\n",
    "scf_conv = data['input.scf_conv'][0]\n",
    "energy_conv = data['input.energy_conv'][0]\n",
    "force_conv = data['input.force_conv'][0]\n",
    "vdw_corr = data['input.vdw_corr'][0]\n",
    "pseudo = data['input.pseudo'][0]\n",
    "spin_polar = data['input.spin_polar'][0]\n",
    "hubbard_U_on = data['input.hubbard_U_on'][0]\n",
    "if hubbard_U_on:\n",
    "    hubbard_projector = data['input.hubbard_projector'][0]\n",
    "    hubbard_U_values = data['input.hubbard_U_values'][0]\n",
    "    hubbard_U_orbitals = data['input.hubbard_U_orbitals'][0]\n",
    "else:\n",
    "    hubbard_projector = None\n",
    "    hubbard_U_values = None\n",
    "    hubbard_U_orbitals = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_params = {'pseudopotential':pseudo, 'vdw_correction':vdw_corr, 'kmesh':[k_x,k_y,k_z], 'kinetic_energy_cutoff':KE_cutoff, 'ionic_steps':i_steps, 'electronic_steps':e_steps, \n",
    "               'scf_convergence_criteria':scf_conv, 'energy_convergence_criteria':energy_conv, 'force_convergence_criteria':force_conv, \n",
    "               'spin_polarization':spin_polar, 'Hubbard_U':hubbard_U_on, 'Hubbard_projector':hubbard_projector, 'Hubbard_U_values':hubbard_U_values, 'Hubbard_U_orbital':hubbard_U_orbitals}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sim(name,struct,sym,**kwargs):\n",
    "    \"\"\"\n",
    "    Generate quantum espresso input files using pymatgen's PWInput class\n",
    "    \n",
    "    Inputs:\n",
    "        name: chosen name for your simulation (i.e. ionic_relax)\n",
    "        struct: pymatgen structure object \n",
    "    Outputs: \n",
    "        n/a\n",
    "    **kwargs:\n",
    "        dictionaries to input to pymatgen's PWInput object\n",
    "    \"\"\"\n",
    "    # Prepare dict of pseudopotentials (i.e. {'Mg': 'Mg.upf', 'O': 'O.upf'})\n",
    "    elements = np.unique([site.species.elements[0].symbol for site in struct.sites])\n",
    "    pseudo_dict = dict(zip(elements,[f\"{element}.upf\" for element in elements]))\n",
    "\n",
    "    # Define input set\n",
    "    input_set = PWInput(structure=struct,\n",
    "                        pseudo=pseudo_dict,\n",
    "                        **kwargs) # dictionaries corresponding to blocks in QE input files\n",
    "\n",
    "    input_set.write_file(filename=f'{name}.in')\n",
    "    # if we want to impose symmetry we remove the CELL_PARAMETERS card from qe in file\n",
    "    if sym != 0:      \n",
    "        with open(f'{name}.in') as f1:\n",
    "            lines = f1.readlines()\n",
    "\n",
    "        with open('tmp.in', 'w') as f2:\n",
    "            f2.writelines(lines[:-4])\n",
    "            \n",
    "        os.rename('tmp.in', f'{name}.in')\n",
    "    \n",
    "def run_sim(name,struct,pseudo):\n",
    "    \"\"\"\n",
    "    Submit quantum espresso runs to HPC clusters on nanoHUB\n",
    "    \n",
    "    Inputs:\n",
    "        name: chosen name for your simulation (i.e. ionic_relax)\n",
    "        struct: pymatgen structure object \n",
    "    Outputs: \n",
    "        n/a\n",
    "    \"\"\"\n",
    "    # Write input and output files\n",
    "    input_file = open(f'{name}.in','a')\n",
    "    input_file.close()\n",
    "\n",
    "    output_file = open(f'{name}.out', 'w')\n",
    "    output_file.close()\n",
    "    \n",
    "    # Set up commands and files\n",
    "    elements = np.unique([site.species.elements[0].symbol for site in struct.sites])\n",
    "    pseudo_arg = \"\".join([f\"-i ./pseudo/pseudo_{pseudo}_PBEsol/{element}.upf \" for element in elements])\n",
    "    COMMAND = f\"espresso-7.1_pw > {output_file.name}\"\n",
    "    \n",
    "    # Run simulation (1 node, 64 cpus, 24 hour walltime)\n",
    "    !submit -n 64 -w '8:00:00' --noquota -e QE_DISABLE_GGA_PBE=0 --runName {name} {pseudo_arg} {COMMAND} -i {input_file.name}  \n",
    "\n",
    "# Define helper functions for QE    \n",
    "def get_qe_outputs_relax(file):\n",
    "    \"\"\"\n",
    "    Extract outputs (energies, forces, structures) from qe .stdout files\n",
    "    \n",
    "    inputs:\n",
    "        file: path to the file we want to extract outputs from\n",
    "    outputs:\n",
    "        dict: dictionary of the extracted outputs\n",
    "    \"\"\"\n",
    "    \n",
    "    output = open(file, \"r\")\n",
    "    lines = output.readlines()\n",
    "    iE = [] # energy at each ionic step, Ry\n",
    "    eE = [[]] # energy at each electronic step, Ry\n",
    "    P = [] # pressure, kbar\n",
    "    F = [] # total force, Ry/au\n",
    "    stresses = [] # stress tensor, kbar\n",
    "    structures = [] # pymatgen structure objects, angstrom\n",
    "\n",
    "    # Check for certain tags on lines, add variables to lists\n",
    "    for i,line in enumerate(lines):\n",
    "        if 'total energy' in line and '!' not in line and 'The' not in line:\n",
    "            eE[-1].append(float(line.split()[3]))\n",
    "        elif 'total energy' in line and '!' in line:\n",
    "            eE.append([])\n",
    "            iE.append(float(line.split()[4]))\n",
    "        elif 'P=' in line:\n",
    "            P.append(float(line.split()[5]))\n",
    "            stresses.append(np.array([lines[i+1].split()[3:6],lines[i+2].split()[3:6],lines[i+3].split()[3:6]]).astype(float))\n",
    "        elif \"Total force\" in line:\n",
    "            F.append(float(line.split()[3]))\n",
    "        elif 'CELL_PARAMETERS' in line:\n",
    "            try:\n",
    "                if 'alat' in line:\n",
    "                    scale = float(line.split()[-1].split(')')[0])*0.529177\n",
    "                else:\n",
    "                    scale = 1.0\n",
    "                lattice = scale*np.array([lines[i+1].split(),lines[i+2].split(),lines[i+3].split()]).astype(float)\n",
    "                sites = []\n",
    "                atoms = []\n",
    "                j=6\n",
    "                while (\"End\" not in lines[i+j].strip()) and (lines[i+j].strip()!=\"\"):\n",
    "                    sites.append(np.array(lines[i+j].split()[1:]).astype(float))\n",
    "                    atoms.append(lines[i+j].split()[0])\n",
    "                    j=j+1\n",
    "                lattice_obj = Lattice(lattice)\n",
    "                print(lattice, atoms, sites)\n",
    "                test_struct = Structure(lattice,atoms,sites)\n",
    "                structures.append(test_struct)\n",
    "            except:\n",
    "                pass\n",
    "    eE = eE[:-1]\n",
    "\n",
    "    # return output dictionary\n",
    "    return {'ionic_energies':iE,'electronic_energies':eE,'pressures':P,'forces':F,'stresses':stresses,'structures':structures}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electron_dict = {'electron_maxstep':e_steps,'conv_thr':scf_conv}\n",
    "\n",
    "if is_metal:\n",
    "    system_dict = {'ecutwfc':int(KE_cutoff),'occupations':'smearing','smearing':'gauss','degauss':0.02,'vdw_corr':vdw_corr}\n",
    "else:\n",
    "    system_dict = {'ecutwfc':int(KE_cutoff),'vdw_corr':vdw_corr}\n",
    "    \n",
    "if spin_polar:\n",
    "    electron_dict['mixing_beta']=0.3\n",
    "    system_dict['nspin']=2\n",
    "    for i in range(n_atom_types):\n",
    "        system_dict['starting_magnetization('+str(i+1)+')']=0.6\n",
    "        if not is_metal:\n",
    "            system_dict['occupations']='smearing'\n",
    "            system_dict['smearing']='gauss'\n",
    "            system_dict['degauss']=0.02\n",
    "            \n",
    "def add_hubbard(name,struct,hubbard_projector,hubbard_U_values):\n",
    "    h_lines = ['HUBBARD {'+hubbard_projector+'} \\n']\n",
    "    elements = np.unique([site.species.elements[0].symbol for site in struct.sites])\n",
    "    for e in elements:\n",
    "        u = hubbard_U_values[e]\n",
    "        o = hubbard_U_orbitals[e] \n",
    "        h_lines.append(f'U {e}-{o} {u}\\n')\n",
    "            \n",
    "    f = open(f'{name}.in','r')\n",
    "    lines = f.readlines()\n",
    "    for line in h_lines:\n",
    "        lines.append(line)\n",
    "    f_new = open('tmp.in','w')\n",
    "    f_new.writelines(lines)\n",
    "    f.close()\n",
    "    f_new.close()\n",
    "    \n",
    "    os.rename('tmp.in', f'{name}.in')\n",
    "    \n",
    "if hubbard_U_on:\n",
    "    electron_dict['mixing_beta']=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pymatgen Strain objects from matrices\n",
    "# # Generate strain matrices\n",
    "strain_matrices = []\n",
    "for ind in [(0, 0), (1, 1), (2, 2)]:\n",
    "    for amount in strains:\n",
    "        strain = Strain.from_index_amount(ind, amount)\n",
    "        strain_matrices.append(strain)\n",
    "        \n",
    "for ind in [(0, 1), (0, 2), (1, 2)]:\n",
    "    for amount in shears:\n",
    "        strain = Strain.from_index_amount(ind, amount)\n",
    "        strain_matrices.append(strain)\n",
    "\n",
    "# Generate deformed structures\n",
    "deformations = []\n",
    "\n",
    "for s_mat in strain_matrices:\n",
    "    deform_matrix = s_mat.get_deformation_matrix()\n",
    "    deformations.append(deform_matrix)\n",
    "    \n",
    "strain_arrays = [np.array(s) for s in strain_matrices]\n",
    "\n",
    "# if sym_red:\n",
    "#     sym_dict = symmetry_reduce(deformations, struct)\n",
    "#     deformations = list(sym_dict)\n",
    "\n",
    "#     strain_mats_reduced = [Strain.from_deformation(defo) for defo in deformations]\n",
    "#     strain_mats = strain_mats_reduced\n",
    "    \n",
    "deform_structs = [defo.apply_to_structure(struct) for defo in deformations]\n",
    "deform_struct_dicts = [defo_struct.as_dict() for defo_struct in deform_structs]\n",
    "    \n",
    "# Calculate each stress tensor\n",
    "system_dict = {'ecutwfc':KE_cutoff,'vdw_corr':vdw_corr}\n",
    "electron_dict = {'electron_maxstep':e_steps,'conv_thr':scf_conv}\n",
    "\n",
    "stress_tensors = []\n",
    "stress_arrays = []\n",
    "energies = []\n",
    "for i,d_struct in enumerate(deform_structs):\n",
    "    print(f'Running calculation on deformed structure {i} out of {len(deform_structs)}')\n",
    "\n",
    "    make_sim(\"relax\", d_struct, sym=0,\n",
    "             control={'pseudo_dir':'./',\n",
    "                      'calculation':'relax',\n",
    "                      'outdir':'./',\n",
    "                      'tstress':True,\n",
    "                      'nstep':i_steps,\n",
    "                      'etot_conv_thr':energy_conv,\n",
    "                      'forc_conv_thr':force_conv,\n",
    "                      'disk_io':'nowf'},\n",
    "             system=system_dict,\n",
    "             electrons=electron_dict,\n",
    "             kpoints_grid=[k_x,k_y,k_z])\n",
    "    \n",
    "    # Add Hubbard U correction if needed\n",
    "    if hubbard_U_on:\n",
    "        add_hubbard(\"relax\", struct, hubbard_projector, hubbard_U_values)\n",
    "\n",
    "    run_sim(\"relax\",d_struct,pseudo)\n",
    "    \n",
    "    try:\n",
    "        relax_dict = get_qe_outputs_relax('relax.stdout')\n",
    "    except:\n",
    "        print('Getting Relax Dictionary Failed')\n",
    "        \n",
    "    s_tensor = -Stress(relax_dict['stresses'][-1]/10)  # convert kbar to GPa\n",
    "    stress_tensors.append(s_tensor)\n",
    "    stress_arrays.append(np.array(s_tensor))\n",
    "    \n",
    "    energies.append(relax_dict['ionic_energies'][-1]*13.605684958731/struct.composition.get_integer_formula_and_factor()[1])\n",
    "    \n",
    "    os.mkdir(f'strain_{i}-{len(deform_structs)}')\n",
    "    os.system(f'mv relax* strain_{i}-{len(deform_structs)}')\n",
    "    os.system('rm -r pw*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit elastic tensor\n",
    "elastic_tensor = ElasticTensor.from_pseudoinverse(strains=strain_matrices,stresses=stress_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mechanical properties\n",
    "# # Bulk modulus\n",
    "k_reuss = elastic_tensor.k_reuss\n",
    "k_voigt = elastic_tensor.k_voigt\n",
    "k_vrh = elastic_tensor.k_vrh\n",
    "# # Shear modulus\n",
    "g_reuss = elastic_tensor.g_reuss\n",
    "g_voigt = elastic_tensor.g_voigt\n",
    "g_vrh = elastic_tensor.g_vrh\n",
    "# # Homogeneous poisson\n",
    "poisson = elastic_tensor.homogeneous_poisson\n",
    "# # Young's modulus\n",
    "y_mod = elastic_tensor.y_mod*1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DB(OUTPUTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.save('external_pressure',ext_press)\n",
    "db.save('strain_matrices',np.array(strain_arrays))\n",
    "db.save('stress_tensors', np.array(stress_arrays))\n",
    "db.save('deformed_structures', deform_struct_dicts)\n",
    "db.save('energies', energies)\n",
    "db.save('elastic_tensor', elastic_tensor.voigt)\n",
    "db.save('C11',elastic_tensor.voigt[0][0])\n",
    "db.save('C12',elastic_tensor.voigt[1][0])\n",
    "db.save('C13',elastic_tensor.voigt[2][0])\n",
    "db.save('C14',elastic_tensor.voigt[3][0])\n",
    "db.save('C15',elastic_tensor.voigt[4][0])\n",
    "db.save('C16',elastic_tensor.voigt[5][0])\n",
    "db.save('C22',elastic_tensor.voigt[1][1])\n",
    "db.save('C23',elastic_tensor.voigt[2][1])\n",
    "db.save('C24',elastic_tensor.voigt[3][1])\n",
    "db.save('C25',elastic_tensor.voigt[4][1])\n",
    "db.save('C26',elastic_tensor.voigt[5][1])\n",
    "db.save('C33',elastic_tensor.voigt[2][2])\n",
    "db.save('C34',elastic_tensor.voigt[3][2])\n",
    "db.save('C35',elastic_tensor.voigt[4][2])\n",
    "db.save('C36',elastic_tensor.voigt[5][2])\n",
    "db.save('C44',elastic_tensor.voigt[3][3])\n",
    "db.save('C45',elastic_tensor.voigt[4][3])\n",
    "db.save('C46',elastic_tensor.voigt[5][3])\n",
    "db.save('C55',elastic_tensor.voigt[4][4])\n",
    "db.save('C56',elastic_tensor.voigt[5][4])\n",
    "db.save('C66',elastic_tensor.voigt[5][5])\n",
    "db.save('bulk_modulus_reuss',k_reuss)\n",
    "db.save('bulk_modulus_voigt',k_voigt)\n",
    "db.save('bulk_modulus_vrh',k_vrh)\n",
    "db.save('shear_modulus_reuss',g_reuss)\n",
    "db.save('shear_modulus_voigt',g_voigt)\n",
    "db.save('shear_modulus_vrh',g_vrh)\n",
    "db.save('homogeneous_poisson',poisson)\n",
    "db.save('youngs_modulus',y_mod)\n",
    "db.save('calc_params',calc_params)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python3 (MatProject)",
   "language": "python",
   "name": "matproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
